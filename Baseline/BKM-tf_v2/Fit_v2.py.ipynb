{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60a7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "# from BHDVCS_tf import BHDVCStf\n",
    "from BHDVCS_tf import TotalFLayer\n",
    "from BHDVCS_tf import DvcsData\n",
    "from BHDVCS_tf import cffs_from_globalModel\n",
    "from BHDVCS_tf import F2VsPhi as F2VsPhitf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from scipy.stats import chisquare\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7fb212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"PseudoKM15_New_FormFactor.csv\", dtype=np.float64)\n",
    "df = df.rename(columns={\"sigmaF\": \"errF\"})\n",
    "\n",
    "N_data = []\n",
    "start_index = []\n",
    "n_total = 0\n",
    "Total_Sets = 195\n",
    "for i in range(Total_Sets):\n",
    "  TempFvalSilces=df[df[\"#Set\"]==i+1]\n",
    "  TempFvals=TempFvalSilces[\"F\"]\n",
    "  start_index = np.append(start_index, n_total)\n",
    "  N_data = np.append(N_data, TempFvals.size)\n",
    "  n_total = n_total + TempFvals.size\n",
    "\n",
    "data = DvcsData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbf605",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "kinematics = tf.keras.Input(shape=(7))\n",
    "x1 = tf.keras.layers.Dense(200, activation=\"relu\", kernel_initializer=initializer)(kinematics)\n",
    "x2 = tf.keras.layers.Dense(200, activation=\"relu\", kernel_initializer=initializer)(x1)\n",
    "outputs = tf.keras.layers.Dense(4, activation=\"linear\", kernel_initializer=initializer)(x2)\n",
    "# noncffInputs = tf.keras.Input(shape=(7))\n",
    "# #### phi, kin1, kin2, kin3, kin4, F1, F2 ####\n",
    "# total_FInputs = tf.keras.layers.concatenate([noncffInputs,outputs])\n",
    "TotalF = TotalFLayer()(outputs)\n",
    "\n",
    "tfModel = tf.keras.Model(inputs=kinematics, outputs = TotalF, name=\"tfmodel\")\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0000005, patience=100)\n",
    "\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0085, df.shape[0]/1, 0.96, staircase=False, name=None\n",
    ")\n",
    "\n",
    "\n",
    "tfModel.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(lr),\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "Wsave = tfModel.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e50a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/195 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tfModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6476/2339280036.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mtfModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWsave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#   hist = tfModel.fit([setI.Kinematics, setI.XnoCFF], setI.sampleY(), # one replica of samples from F vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfModel' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#!!High-overfitting from batch_size 1, 2 100 node hidden layers no validation data, huge number of epochs!!#\n",
    "# Over-fitting to F will likely not reflect well in CFF predictions\n",
    "\n",
    "#Number of kinematic sets\n",
    "by_set = []\n",
    "number = 0\n",
    "for i in tqdm(range(Total_Sets)):\n",
    "    \n",
    "  setI = data.getSet(i,start_index,N_data)\n",
    "\n",
    "#   Data = pd.concat([setI.Kinematics, setI.XnoCFF], axis=1)\n",
    "\n",
    "#   Data_v2 = pd.concat([Data, pd.DataFrame(setI.sampleY())], axis=1)\n",
    "\n",
    "#   Data_v3 = Data_v2.rename(columns={Data_v2.columns[11]: 'F'})\n",
    "\n",
    "#   y = Data_v3['F']\n",
    "#   x = Data_v3.drop(['F'],axis=1)\n",
    "    \n",
    "#   train_X, test_X, train_Y, test_Y = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "\n",
    "  tfModel.set_weights(Wsave)\n",
    "\n",
    "#   hist = tfModel.fit([setI.Kinematics, setI.XnoCFF], setI.sampleY(), # one replica of samples from F vals\n",
    "                        \n",
    "#   epochs=150, verbose=0, batch_size=16)\n",
    "\n",
    "#   hist = tfModel.fit(train_X,train_Y, validation_data = (test_X, test_Y),  # one replica of samples from F vals\n",
    "                        \n",
    "#   epochs=150, verbose=0, batch_size=16)\n",
    "\n",
    "  hist = tfModel.fit(setI.XnoCFF, setI.sampleY(), # one replica of samples from F vals\n",
    "                        \n",
    "  epochs=50, verbose=0, batch_size=2056)\n",
    "  \n",
    "  cffs = cffs_from_globalModel(tfModel, setI.Kinematics, numHL=2)\n",
    "\n",
    "  by_set.append(cffs)\n",
    "  \n",
    "df = pd.DataFrame(by_set)\n",
    "df.to_csv(f\"bySetCFFs(195).csv\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val_loss'], loc='upper left')\n",
    "plt.savefig('Loss_Plot_V3_tuned.png')\n",
    "# df.to_csv(f\"/project/ptgroup/Devin/ANN/BKM_T/CFF_Data/bySetCFFs(195)_\" + sys.argv[1] + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1028006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       k     QQ    x_b      t  phi_x     QQ    x_b      t     k       F1  \\\n",
      "0   5.75  1.820  0.343 -0.172    7.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "1   5.75  1.820  0.343 -0.172   22.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "2   5.75  1.820  0.343 -0.172   37.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "3   5.75  1.820  0.343 -0.172   52.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "4   5.75  1.820  0.343 -0.172   67.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "5   5.75  1.820  0.343 -0.172   82.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "6   5.75  1.820  0.343 -0.172   97.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "7   5.75  1.820  0.343 -0.172  112.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "8   5.75  1.820  0.343 -0.172  127.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "9   5.75  1.820  0.343 -0.172  142.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "10  5.75  1.820  0.343 -0.172  157.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "11  5.75  1.820  0.343 -0.172  172.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "12  5.75  1.820  0.343 -0.172  187.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "13  5.75  1.820  0.343 -0.172  202.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "14  5.75  1.820  0.343 -0.172  217.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "15  5.75  1.820  0.343 -0.172  232.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "16  5.75  1.820  0.343 -0.172  247.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "17  5.75  1.820  0.343 -0.172  262.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "18  5.75  1.820  0.343 -0.172  277.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "19  5.75  1.820  0.343 -0.172  292.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "20  5.75  1.820  0.343 -0.172  307.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "21  5.75  1.820  0.343 -0.172  322.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "22  5.75  1.820  0.343 -0.172  337.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "23  5.75  1.820  0.343 -0.172  352.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "24  5.75  1.933  0.368 -0.232    7.5  1.933  0.368 -0.232  5.75  0.61351   \n",
      "\n",
      "         F2         F  \n",
      "0   1.09312  0.114522  \n",
      "1   1.09312  0.115027  \n",
      "2   1.09312  0.095090  \n",
      "3   1.09312  0.081541  \n",
      "4   1.09312  0.087732  \n",
      "5   1.09312  0.074172  \n",
      "6   1.09312  0.068135  \n",
      "7   1.09312  0.062688  \n",
      "8   1.09312  0.060030  \n",
      "9   1.09312  0.062745  \n",
      "10  1.09312  0.050994  \n",
      "11  1.09312  0.062569  \n",
      "12  1.09312  0.050878  \n",
      "13  1.09312  0.051921  \n",
      "14  1.09312  0.052389  \n",
      "15  1.09312  0.055404  \n",
      "16  1.09312  0.068699  \n",
      "17  1.09312  0.070834  \n",
      "18  1.09312  0.073288  \n",
      "19  1.09312  0.086166  \n",
      "20  1.09312  0.097147  \n",
      "21  1.09312  0.101781  \n",
      "22  1.09312  0.104732  \n",
      "23  1.09312  0.113783  \n",
      "24  0.94474  0.078069  \n"
     ]
    }
   ],
   "source": [
    "# setI = data.getSet(0,start_index,N_data)\n",
    "\n",
    "# Data = pd.concat([setI.Kinematics, setI.XnoCFF], axis=1)\n",
    "\n",
    "# Data_v2 = pd.concat([Data, pd.DataFrame(setI.sampleY())], axis=1)\n",
    "\n",
    "# Data_v3 = Data_v2.rename(columns={Data_v2.columns[11]: 'F'})\n",
    "\n",
    "# y = Data_v3['F']\n",
    "# x = Data_v3.drop(['F'],axis=1)\n",
    "\n",
    "# # print(y)\n",
    "# # trainX, testX, trainY, testY = trn_tst(x,y)\n",
    "\n",
    "# # trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.1)\n",
    "\n",
    "# print(Data_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce28df73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    0.072894\n",
       "12    0.058765\n",
       "14    0.056142\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ec4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60a7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "# from BHDVCS_tf import BHDVCStf\n",
    "from BHDVCS_tf import TotalFLayer\n",
    "from BHDVCS_tf import DvcsData\n",
    "from BHDVCS_tf import cffs_from_globalModel\n",
    "from BHDVCS_tf import F2VsPhi as F2VsPhitf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from scipy.stats import chisquare\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7fb212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"PseudoKM15_New_FormFactor.csv\", dtype=np.float64)\n",
    "df = df.rename(columns={\"sigmaF\": \"errF\"})\n",
    "\n",
    "N_data = []\n",
    "start_index = []\n",
    "n_total = 0\n",
    "Total_Sets = 195\n",
    "for i in range(Total_Sets):\n",
    "  TempFvalSilces=df[df[\"#Set\"]==i+1]\n",
    "  TempFvals=TempFvalSilces[\"F\"]\n",
    "  start_index = np.append(start_index, n_total)\n",
    "  N_data = np.append(N_data, TempFvals.size)\n",
    "  n_total = n_total + TempFvals.size\n",
    "\n",
    "data = DvcsData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bbf605",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "kinematics = tf.keras.Input(shape=(7))\n",
    "x1 = tf.keras.layers.Dense(200, activation=\"relu\", kernel_initializer=initializer)(kinematics)\n",
    "x2 = tf.keras.layers.Dense(200, activation=\"relu\", kernel_initializer=initializer)(x1)\n",
    "outputs = tf.keras.layers.Dense(4, activation=\"linear\", kernel_initializer=initializer)(x2)\n",
    "# noncffInputs = tf.keras.Input(shape=(7))\n",
    "# #### phi, kin1, kin2, kin3, kin4, F1, F2 ####\n",
    "# total_FInputs = tf.keras.layers.concatenate([noncffInputs,outputs])\n",
    "# TotalF = TotalFLayer()(outputs)\n",
    "\n",
    "tfModel = tf.keras.Model(inputs=kinematics, outputs = outputs, name=\"tfmodel\")\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0000005, patience=100)\n",
    "\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0085, df.shape[0]/1, 0.96, staircase=False, name=None\n",
    ")\n",
    "\n",
    "\n",
    "tfModel.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(lr),\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "Wsave = tfModel.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e50a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/195 [00:00<?, ?it/s]2023-06-18 21:04:39.183218: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-06-18 21:04:39.183242: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:221] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "  0%|                                                   | 0/195 [00:00<?, ?it/s]\n",
      "2023-06-18 21:04:39.183260: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:622 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Exception encountered when calling layer 'dense_6' (type Dense).\n\n{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} Attempting to perform BLAS operation using StreamExecutor without BLAS support [Op:MatMul]\n\nCall arguments received by layer 'dense_6' (type Dense):\n  • inputs=tf.Tensor(shape=(25, 7), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5430/3379224724.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#   epochs=150, verbose=0, batch_size=16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   hist = tfModel.fit(setI.XnoCFF, setI.sampleY(), # one replica of samples from F vals\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   epochs=50, verbose=0, batch_size=2056)\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7215\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Exception encountered when calling layer 'dense_6' (type Dense).\n\n{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} Attempting to perform BLAS operation using StreamExecutor without BLAS support [Op:MatMul]\n\nCall arguments received by layer 'dense_6' (type Dense):\n  • inputs=tf.Tensor(shape=(25, 7), dtype=float32)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#!!High-overfitting from batch_size 1, 2 100 node hidden layers no validation data, huge number of epochs!!#\n",
    "# Over-fitting to F will likely not reflect well in CFF predictions\n",
    "\n",
    "#Number of kinematic sets\n",
    "by_set = []\n",
    "number = 0\n",
    "for i in tqdm(range(Total_Sets)):\n",
    "    \n",
    "  setI = data.getSet(i,start_index,N_data)\n",
    "\n",
    "#   Data = pd.concat([setI.Kinematics, setI.XnoCFF], axis=1)\n",
    "\n",
    "#   Data_v2 = pd.concat([Data, pd.DataFrame(setI.sampleY())], axis=1)\n",
    "\n",
    "#   Data_v3 = Data_v2.rename(columns={Data_v2.columns[11]: 'F'})\n",
    "\n",
    "#   y = Data_v3['F']\n",
    "#   x = Data_v3.drop(['F'],axis=1)\n",
    "    \n",
    "#   train_X, test_X, train_Y, test_Y = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "\n",
    "  tfModel.set_weights(Wsave)\n",
    "\n",
    "#   hist = tfModel.fit([setI.Kinematics, setI.XnoCFF], setI.sampleY(), # one replica of samples from F vals\n",
    "                        \n",
    "#   epochs=150, verbose=0, batch_size=16)\n",
    "\n",
    "#   hist = tfModel.fit(train_X,train_Y, validation_data = (test_X, test_Y),  # one replica of samples from F vals\n",
    "                        \n",
    "#   epochs=150, verbose=0, batch_size=16)\n",
    "\n",
    "  hist = tfModel.fit(setI.XnoCFF, setI.sampleY(), # one replica of samples from F vals\n",
    "                        \n",
    "  epochs=50, verbose=0, batch_size=2056)\n",
    "  \n",
    "  cffs = cffs_from_globalModel(tfModel, setI.Kinematics, numHL=2)\n",
    "\n",
    "  by_set.append(cffs)\n",
    "  \n",
    "df = pd.DataFrame(by_set)\n",
    "df.to_csv(f\"bySetCFFs(195).csv\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val_loss'], loc='upper left')\n",
    "plt.savefig('Loss_Plot_V3_tuned.png')\n",
    "# df.to_csv(f\"/project/ptgroup/Devin/ANN/BKM_T/CFF_Data/bySetCFFs(195)_\" + sys.argv[1] + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1028006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       k     QQ    x_b      t  phi_x     QQ    x_b      t     k       F1  \\\n",
      "0   5.75  1.820  0.343 -0.172    7.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "1   5.75  1.820  0.343 -0.172   22.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "2   5.75  1.820  0.343 -0.172   37.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "3   5.75  1.820  0.343 -0.172   52.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "4   5.75  1.820  0.343 -0.172   67.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "5   5.75  1.820  0.343 -0.172   82.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "6   5.75  1.820  0.343 -0.172   97.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "7   5.75  1.820  0.343 -0.172  112.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "8   5.75  1.820  0.343 -0.172  127.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "9   5.75  1.820  0.343 -0.172  142.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "10  5.75  1.820  0.343 -0.172  157.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "11  5.75  1.820  0.343 -0.172  172.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "12  5.75  1.820  0.343 -0.172  187.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "13  5.75  1.820  0.343 -0.172  202.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "14  5.75  1.820  0.343 -0.172  217.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "15  5.75  1.820  0.343 -0.172  232.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "16  5.75  1.820  0.343 -0.172  247.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "17  5.75  1.820  0.343 -0.172  262.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "18  5.75  1.820  0.343 -0.172  277.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "19  5.75  1.820  0.343 -0.172  292.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "20  5.75  1.820  0.343 -0.172  307.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "21  5.75  1.820  0.343 -0.172  322.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "22  5.75  1.820  0.343 -0.172  337.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "23  5.75  1.820  0.343 -0.172  352.5  1.820  0.343 -0.172  5.75  0.68309   \n",
      "24  5.75  1.933  0.368 -0.232    7.5  1.933  0.368 -0.232  5.75  0.61351   \n",
      "\n",
      "         F2         F  \n",
      "0   1.09312  0.114522  \n",
      "1   1.09312  0.115027  \n",
      "2   1.09312  0.095090  \n",
      "3   1.09312  0.081541  \n",
      "4   1.09312  0.087732  \n",
      "5   1.09312  0.074172  \n",
      "6   1.09312  0.068135  \n",
      "7   1.09312  0.062688  \n",
      "8   1.09312  0.060030  \n",
      "9   1.09312  0.062745  \n",
      "10  1.09312  0.050994  \n",
      "11  1.09312  0.062569  \n",
      "12  1.09312  0.050878  \n",
      "13  1.09312  0.051921  \n",
      "14  1.09312  0.052389  \n",
      "15  1.09312  0.055404  \n",
      "16  1.09312  0.068699  \n",
      "17  1.09312  0.070834  \n",
      "18  1.09312  0.073288  \n",
      "19  1.09312  0.086166  \n",
      "20  1.09312  0.097147  \n",
      "21  1.09312  0.101781  \n",
      "22  1.09312  0.104732  \n",
      "23  1.09312  0.113783  \n",
      "24  0.94474  0.078069  \n"
     ]
    }
   ],
   "source": [
    "# setI = data.getSet(0,start_index,N_data)\n",
    "\n",
    "# Data = pd.concat([setI.Kinematics, setI.XnoCFF], axis=1)\n",
    "\n",
    "# Data_v2 = pd.concat([Data, pd.DataFrame(setI.sampleY())], axis=1)\n",
    "\n",
    "# Data_v3 = Data_v2.rename(columns={Data_v2.columns[11]: 'F'})\n",
    "\n",
    "# y = Data_v3['F']\n",
    "# x = Data_v3.drop(['F'],axis=1)\n",
    "\n",
    "# # print(y)\n",
    "# # trainX, testX, trainY, testY = trn_tst(x,y)\n",
    "\n",
    "# # trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.1)\n",
    "\n",
    "# print(Data_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce28df73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    0.072894\n",
       "12    0.058765\n",
       "14    0.056142\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ec4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hD3yuudRogq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from BHDVCS_tf import BHDVCStf\n",
        "from BHDVCS_tf import TotalFLayer\n",
        "from BHDVCS_tf import DvcsData\n",
        "from BHDVCS_tf import cffs_from_globalModel\n",
        "from BHDVCS_tf import F2VsPhi as F2VsPhitf\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "ddf=pd.read_csv(r\"/content/Book 8.csv\",header=0,\n",
        "                usecols=[\"# of layers\", \"nodes first layer\", \"decreasing nodes\",\n",
        "                         \"activation function\",\"initial learning rate\",\"decay rate\"])\n",
        "#note to call funcitons use ddf.iloc[row][column] with normal python index at 0\n",
        "\n",
        "#for j in range(len(ddf.iloc[:,0])):\n",
        "for j in range(len(ddf.iloc[:,0])):\n",
        "  df = pd.read_csv(r\"/content/PseudoKM15_New_FormFactor.csv\", dtype=np.float64)\n",
        "#first is what the column is called in csv, second is new name of the column in the data frame.\n",
        "  df = df.rename(columns={\"sigmaF\": \"errF\"})\n",
        "\n",
        "  data = DvcsData(df)\n",
        "\n",
        "  initializer = tf.keras.initializers.HeNormal()\n",
        "\n",
        "\n",
        "  kinematics = tf.keras.Input(shape=(4))\n",
        "\n",
        "  k=0\n",
        "  while k <ddf.iloc[j,0]:\n",
        "    if k==0:\n",
        "      x0=tf.keras.layers.Dense(ddf.iloc[j][1], activation=ddf.iloc[j][3], kernel_initializer=initializer)(kinematics)\n",
        "    else:\n",
        "      xo=x0\n",
        "      x0=tf.keras.layers.Dense(ddf.iloc[j][1]-k*ddf.iloc[j][2], activation=ddf.iloc[j][3], kernel_initializer=initializer)(xo)\n",
        "      #x0=tf.keras.layers.Dense(ddf.iloc[j][1]-k*ddf.iloc[j][2], activation=ddf.iloc[j][3], kernel_initializer=initializer)(x0) the next stepp\n",
        "    k=k+1\n",
        "\n",
        "  #x2 = tf.keras.layers.Dense(100, activation=\"linear\", kernel_initializer=initializer)(x1)\n",
        "  outputs = tf.keras.layers.Dense(4, activation=\"linear\", kernel_initializer=initializer)(x0)\n",
        "  noncffInputs = tf.keras.Input(shape=(7))\n",
        "#### phi, kin1, kin2, kin3, kin4, F1, F2 ####, putting the noncff and the cff gotten from the NN together.\n",
        "  total_FInputs = tf.keras.layers.concatenate([noncffInputs,outputs])\n",
        "  TotalF = TotalFLayer()(total_FInputs)\n",
        "\n",
        "# Model puts it all together, input kin and noncff separtly, but together, output the TotalF from above as output single thing\n",
        "  tfModel = tf.keras.Model(inputs=[kinematics, noncffInputs], outputs = TotalF, name=\"tfmodel\")\n",
        "#early stopping jsut stops it if it is bad.\n",
        "  early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0000005, patience=100)\n",
        "\n",
        "#I assume this is the optimizers\n",
        "#this is learning rate, initial learning rate, df is decay steps, decay rate.\n",
        "  lr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    ddf.iloc[j][4], df.shape[0]/1, ddf.iloc[j][5], staircase=False, name=None)\n",
        "\n",
        "#I assume this complies it all\n",
        "  tfModel.compile(optimizer = tf.keras.optimizers.Adam(lr),loss = tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "#returns a numpy array of the wheights used and the biases of each layer\n",
        "  Wsave = tfModel.get_weights()\n",
        "\n",
        "#!!High-overfitting from batch_size 1, 2 100 node hidden layers no validation data, huge number of epochs!!#\n",
        "# Over-fitting to F will likely not reflect well in CFF predictions\n",
        "\n",
        "#Number of kinematic sets\n",
        "  by_set = []\n",
        "  for i in range(15):\n",
        "    setI = data.getSet(i, itemsInSet=45)\n",
        "\n",
        "    tfModel.set_weights(Wsave)\n",
        "#epoch is how many times it runs over the code, set to 100. take\n",
        "    tfModel.fit([setI.Kinematics, setI.XnoCFF], setI.sampleY(), # one replica of samples from F vals\n",
        "                epochs=1001, verbose=0, batch_size=16)\n",
        "\n",
        "    cffs = cffs_from_globalModel(tfModel, setI.Kinematics, numHL=2)\n",
        "\n",
        "    by_set.append(cffs)\n",
        "\n",
        "  df = pd.DataFrame(by_set)\n",
        "\n",
        "  if len(sys.argv) > 1:\n",
        "    df.to_csv('bySetCFFs' + sys.argv[1] + str(j)+'.csv')\n",
        "  else:\n",
        "    df.to_csv('bySetCFFs' + str(j) +'.csv')"
      ]
    }
  ]
}